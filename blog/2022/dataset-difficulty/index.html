<!DOCTYPE html> <html lang="en"> <head> <meta name="google-site-verification" content=""/> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>PoTM - Understanding Dataset Difficulty with V-Usable Information | Viet-Phi Huynh</title> <meta name="author" content="Viet-Phi Huynh"/> <meta name="description" content="Viet-Phi Huynh personal webpage. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://huynhvp.github.io/blog/2022/dataset-difficulty/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Viet-Phi </span>Huynh</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">PoTM - Understanding Dataset Difficulty with V-Usable Information</h1> <p class="post-meta">December 6, 2022</p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>   ·   <a href="/blog/tag/research"> <i class="fas fa-hashtag fa-sm"></i> research</a>     ·   <a href="/blog/category/paper-of-the-month"> <i class="fas fa-tag fa-sm"></i> paper_of_the_month,</a>   <a href="/blog/category/information-theory"> <i class="fas fa-tag fa-sm"></i> information_theory,</a>   <a href="/blog/category/machine-learning"> <i class="fas fa-tag fa-sm"></i> machine_learning</a>   </p> </header> <article class="post-content"> <hr> <p>In this post, I would like to summarize an interesting paper that received the Outstanding Paper Award at ICML 2022: <a href="https://proceedings.mlr.press/v162/ethayarajh22a/ethayarajh22a.pdf" target="_blank" rel="noopener noreferrer">Understanding Dataset Difficulty with V-Usable Information (Ethayarajh et al.)</a>. The paper introduces a novel method for estimating the difficulty of a dataset w.r.t. a model using information theory. Specifically, it proposes \(\mathcal{V}\) - <em>usable information</em> and <em>pointwise</em> \(\mathcal{V}\) - <em>usable information</em> extended from Shannon’s mutual information to measure how much information contained in a dataset \((X, Y)\) (\(X\): input, \(Y\): label for example) or in an instance of \((X, Y)\) is <em>usable</em> by a model \(\mathcal{V}\). Lower value \(\mathcal{V}\) - <em>usable information</em> indicates that the dataset (or the instance) is more difficult for the model \(\mathcal{V}\).</p> <hr> <p><b>Table of Contents</b></p> <ul id="markdown-toc"> <li><a href="#the-lack-of-interpretability-for-estimating-dataset-difficulty-of-related-works-" id="markdown-toc-the-lack-of-interpretability-for-estimating-dataset-difficulty-of-related-works-"><b>The lack of interpretability for estimating dataset difficulty of related works </b></a></li> <li><a href="#shannon-mutual-information-" id="markdown-toc-shannon-mutual-information-"><b>Shannon Mutual Information </b></a></li> <li><a href="#mathcalv-usable-information-or-mathcalv-information-" id="markdown-toc-mathcalv-usable-information-or-mathcalv-information-"><b>\(\mathcal{V}-usable\) information (or \(\mathcal{V}\) information) </b></a></li> <li><a href="#pointwise-mathcalv-information-" id="markdown-toc-pointwise-mathcalv-information-"><b>Pointwise \(\mathcal{V}\) information </b></a></li> <li><a href="#usage-of-mathcalv-information-" id="markdown-toc-usage-of-mathcalv-information-"><b>Usage of \(\mathcal{V}\) information </b></a></li> </ul> <h3 id="the-lack-of-interpretability-for-estimating-dataset-difficulty-of-related-works-"><b>The lack of interpretability for estimating dataset difficulty of related works </b></h3> <ul> <li> <p>Typical strategy of assessing whether a dataset is hard is to benchmark state-of-the-art models on this dataset and compare their performances to human. The bigger gap, the harder the data is considered to be. Since such evaluation is generally done at dataset-scale, it is limited in the capacity of understanding the different difficulty of individual sample in the dataset (which sample is harder than other). Furthermore, classic performance metrics, such as accuracy or F1 score for classification problem, are not suitable for standardized comparison across models and datasets. For example, considering 2 datasets \((X_1, Y_1)\) and \((X_2, Y_2)\) where \(X_1\) (resp. \(X_2\)) is independent of \(Y_1\) (resp. \(Y_2\)), we should expect that they have the same highest level difficulty (\(\mathcal{V}\) - <em>usable information</em> \(\approx\) zero), however, a model can obtain different accuracy on two datasets depending on the frequency of the majority class \(y\) in the dataset.</p> </li> <li> <p>Model-agnostic approaches to estimate the difficulty of a dataset are not able to explain why the dataset is easy for some models and hard for other models.</p> </li> <li> <p>Some approaches consider text-based heuristics such as word identity, input length or learning-based metrics such as training loss, prediction variance as proxies for dataset difficulty. However, they are not as readable as \(\mathcal{V}\) - <em>usable information</em>.</p> </li> </ul> <h3 id="shannon-mutual-information-"><b>Shannon Mutual Information </b></h3> <p>Shannon mutual information between two random variables measures the the amount of information obtained about one random variable (or the change in entropy of one random variable) by observing the other random variable (in the context of dataset difficulty, \(X\) is the input variable and \(Y\) is the label variable):</p> \[I(X, Y) = H(Y) - H(Y \mid X)\] <p>However, because this quantity is calculated with the assumption of infinite computation capacity, it is not suitable in practice as computational constraint is an important aspect to be considered. For example, considering three datasets \((X, Y)\), \((f(X), Y)\) and \((g(X), Y)\) where \(f\), \(g\) is an encrypting function and an useful preprocessing function applied on \(X\), respectively, we should expect that using \(f(X)\) to predict \(Y\): \(f(X) \rightarrow Y\) is harder and using \(g(X)\) to predict \(Y\): \(g(X) \rightarrow Y\) is easier than using \(X\) to predict \(Y\): \(X \rightarrow Y\) as after encrypting \(X\), the information contained in \(X\) becomes less accessible or after pre-processing \(X\), the information contained in \(X\) is exploited more easily. Despite that, the Shannon mutual information \(I(X, Y)\) would not change: \(I(X, Y) = I(f(X), Y) = I(g(x), Y)\) as it allows for unbounded computation, so one can employ arbitrarily complex strategy to decode \(f(X)\) and predict \(Y\) from \(X\).</p> <h3 id="mathcalv-usable-information-or-mathcalv-information-"><b>\(\mathcal{V}-usable\) information (or \(\mathcal{V}\) information) </b></h3> <p>Let \(\mathcal{X}, \mathcal{Y}\) be the sample space of two random variables \(X\), \(Y\) respectively and \(\Omega = \{f: \mathcal{X} \cup \varnothing \rightarrow \mathcal{P}(\mathcal{Y}) \}\) be any mapping function that predicts a distribution over \(\mathcal{Y}\) using the input \(\mathcal{X}\) or no side information \(\varnothing\). The computation-unbounded Shannon mutual information can be rewritten as: \(I(X, Y)=I_{\Omega}(X, Y)\).</p> <p>Under the computational or statistical constraints scenario, only a subset \(\mathcal{V} \subset \Omega\) is allowed to use to predict \(Y\), leading to the definition of \(\mathcal{V}\) information, extended from Shannon mutual information:</p> \[I_{\mathcal{V}}(X, Y) = H_{\mathcal{V}}(Y) - H_{\mathcal{V}}(Y \mid X)\] <p>where \(H_{\mathcal{V}}(Y) = \inf_{f \in \mathcal{V}} \mathbb{E}_{y \sim Y}[-\text{log} \; f[\varnothing](y)]\) and \(H_{\mathcal{V}}(Y \mid X) = \inf_{f \in \mathcal{V}} \mathbb{E}_{y \sim Y, x \sim X}[-\text{log} \; f[x](y)]\).</p> <p>Intuitively, the conditional \(\mathcal{V}-entropy\) \(H_{\mathcal{V}}(Y \mid X )\) (resp. \(\mathcal{V}-entropy\) \(H_{\mathcal{V}}(Y)\)) is smallest expected negative log-likelihood of predicted label \(Y\) given observations \(X\) (resp. no side information \(\varnothing\)).</p> <p>In practice, it is impossible to calculate the true \(\mathcal{V}-information\) as it requires the whole data distribution. Instead, it is empirically estimated on a finite dataset supposed to include samples that i.i.d drawn from the distribution, leading to the gap between the true \(\mathcal{V}-information\) and empirical \(\mathcal{V}-information\). However, if \(\mathcal{V}\) is less complex and the dataset is large, the gap becomes small.</p> <p>In the learning context, \(H_{\mathcal{V}}(Y \mid X )\) is estimated by training (or fine-tuning) a model \(f \in \mathcal{V}\) with cross-entropy loss to minimize the negative log-likelihood of \(Y\) given \(X\): \(\mathbb{E}_{y \sim Y_{train}, x \sim X_{train}}[-\text{log} \; f[x](y)]\), then using the trained model to calculate \(\mathbb{E}_{y \sim Y_{test}, x \sim X_{test}}[-\text{log} \; f[x](y)]\) on test dataset. Similarly, \(H_{\mathcal{V}}(Y)\) is estimated by fitting another model \(f \in \mathcal{V}\) on label distribution.</p> <h3 id="pointwise-mathcalv-information-"><b>Pointwise \(\mathcal{V}\) information </b></h3> <p>\(\mathcal{V}\) information is extended to individual instance \((x, y)\) of random variables \((X, Y)\) under pointwise \(\mathcal{V}\) information \(\textsf{PVI}(x, y)\).</p> \[\textsf{PVI}(x \rightarrow y) = - \text{log} \; g[\varnothing](y) + \text{log} \; g'[x](y)\] <p>where \(g \in \mathcal{V} \; s.t. \mathbb{E}[- \text{log} \; g[\varnothing](Y)] = H_{\mathcal{V}}(Y)\) and \(g' \in \mathcal{V} \; s.t. \mathbb{E}[- \text{log} \; g'[X](Y)] = H_{\mathcal{V}}(Y \mid X)\). Loosely speaking, \(g\) and \(g'\) are models (e.g. BERT) before and after fine-tuning with training samples of \((X, Y)\), and \(\textsf{PVI}(x, y)\) is the difference in log-probability that two models assign to the label \(y\). The higher the \(\textsf{PVI}\), the easier the instance is w.r.t. \(\mathcal{V}\).</p> <p>\(\textsf{PVI}(x, y)\) should only depend on the distribution of \(X\) and \(Y\). Fine-tuning models \(\in \mathcal{V}\) with different size of training set \(\{(x, y)_i\}_{i=1}^k\) should not change this quantity.</p> <p>The estimated \(\mathcal{V}\) information \(\hat{I}_{\mathcal{V}}(X, Y)\) is written as: \(\hat{I}_{\mathcal{V}}(X, Y) = \frac{\sum_i \text{PVI} (x_i, y_i)}{n}.\)</p> <h3 id="usage-of-mathcalv-information-"><b>Usage of \(\mathcal{V}\) information </b></h3> <ol> <li> <p><b>Compare different models \(\mathcal{V}\) for the same dataset \((X, Y)\) by computing \(I_{\mathcal{V}}(X \rightarrow Y)\)</b></p> <p>Following figure shows the test accuracy of 4 models {GPT2-small, BERT-base, BART-base, DistillBERT-base } on SNLI task. Model with higher \(\mathcal{V}-information\) exploits more information from the dataset, leading to better performance (BART-base). <img src="/assets/img/v_information/snli.PNG" alt="" style="width: 40%; display:block; margin-left:auto; margin-right:auto"> <em>(Source: copied from the paper)</em></p> <p>Furthermore, \(\mathcal{V}-information\) can be an early sign of overfitting. At epoch 5, the models start to be less certain about the true label \(\rightarrow\) \(\mathcal{V}-information\) starts to decrease but it can still make correct predictions (test accuracy is stable). Then, at epoch 10, \(\mathcal{V}-information\) reach its lowest value and diverges but it looks like test accuracy is just starting to decline.</p> </li> <li> <p><b>Compare the difficulty of different dataset \((X, Y)\)(s) for the same model \(\mathcal{V}\) by computing \(I_{\mathcal{V}}(X \rightarrow Y)\) </b></p> <p>The dotted lines in figure below show \(BERT-information\)(s) (\(\mathcal{V}\) = BERT) for 3 NLI datasets: CoLA, MultiNLI and SNLI. It is expected that CoLA is the most difficult dataset, then MultiNLI for NLI task addressed by BERT model. <img src="/assets/img/v_information/dataset_diff.PNG" alt="" style="width: 40%; display:block; margin-left:auto; margin-right:auto"> <em>(Source: copied from the paper)</em></p> </li> <li> <p>\(\textsf{PVI}\) can help to spot mislabelled instances where such instances have negative \(\textsf{PVI}\).</p> </li> <li> <p>The \(\textsf{PVI}\) threshold at which predictions become incorrect is similar across datasets. The gold threshold is 0.5 which is useful for cross-dataset comparison.</p> </li> </ol> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Viet-Phi Huynh. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>